{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b3e7b3c1-de58-4522-920e-fe462c93f843",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# COMP3002 Big Data and Cloud Project\n",
    "## Task 1\n",
    "\n",
    "This notebook describes the tasks that you must complete for the first task.  You should complete the work in this notebook and ensure that you regularly commit it to your GitHub classroom.  You can choose to include additional python .py files if you wish to create some helper functions to keep this notebook clean.  Make sure they are committed to the GitHub repository too.\n",
    "\n",
    "### Scenario\n",
    "\n",
    "You are provided with a small sample dataset of Amazon Review Data.  This notebook talks you through the process of loading that data into Spark SQL and asks you to analyse that data.  On the Block Release day on 18th November (Open Cohort) and 20th November (Ford Cohort) you will have access to a larger dataset hosted in the Cloud.  Much of the day will be spent moving your solutions to the cloud, and answering additional questions which will be set on the day.\n",
    "\n",
    "If you do not finish everything during Block Release.  You will have additionl time to reflect on the experience and finalise your code before final submission on 26th November.\n",
    "\n",
    "Amazon Review Data was downloaded from [here](https://jmcauley.ucsd.edu/data/amazon/) but a small sample is provided with this assignment.\n",
    "\n",
    "### Learning Outcomes\n",
    "\n",
    "Remember that the primary aim with this task is not to get the \"correct\" answer, but for you to use the time to become confident with some basic Big Data processing.\n",
    "\n",
    "* **LO1** Understand the principles that allow the processing of big data sets.\n",
    "\n",
    "* **LO3** Understand the limitations of big data technologies for distributed processing.\n",
    "\n",
    "* **LO3** Demonstrate practical skills required to implement big-data solutions using modern large-scale data and compute infrastructures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b84067b2-2981-4903-89ed-45583b8cb56e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Assessment\n",
    "\n",
    "Assessment follows a similar approach to that used previously on the programme.  This small task attracts up to a grade C.  The second task to be released later this term will allow you to stretch to higher grades.\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <th align=\"left\">Grade</th>\n",
    "        <th align=\"left\"><p>Criteria</p></th> \n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>C (50)</td>\n",
    "        <td align=\"left\">\n",
    "            <p>In addition to the requirements for D-grade, the work should:</p>\n",
    "            <ul align=\"left\">\n",
    "                <li align=\"left\">\n",
    "                    <p>Demonstrate the ability to implement a solution to the challenge tasks posed during the block release day using the Spark Cluster.</p>\n",
    "                </li>\n",
    "            </ul>\n",
    "            <p>If the solution is not complete, a C-grade may still be awarded if a strong narrative is provided to explain where further work is needed and what the next steps would be.</p>\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr style=\"background-color: #FBB36B;\">\n",
    "        <td>D (40)</td>\n",
    "        <td align=\"left\">\n",
    "            <p>As this is the passing grade for the project, you must achieve all the learning outcomes.</p>\n",
    "            <p>The work should meet the following minimum criteria:</p>\n",
    "            <ul align=\"left\">\n",
    "                <li align=\"left\">\n",
    "                    <p>Work should be a Jupyter notebook submitted via Github Classrooms with accompanying helper .py files that are free from errors and execute successfully.</p>\n",
    "                </li>\n",
    "                <li align=\"left\">\n",
    "                    <p>The notebook demonstrates that the apprentice can:</p>\n",
    "                    <ol>\n",
    "                        <li align=\"left\">\n",
    "                            <p>Connect to a spark context.</p>\n",
    "                        </li>\n",
    "                        <li align=\"left\">\n",
    "                            <p>Transmit data to Spark.</p>\n",
    "                        </li>\n",
    "                        <li align=\"left\">\n",
    "                            <p>Execute remote transformations and actions on Spark.</p>\n",
    "                        </li>\n",
    "                        <li align=\"left\">\n",
    "                            <p>Retrieve outputs and present them in a suitable manner.</p>\n",
    "                        </li>\n",
    "                    </ol>\n",
    "                </li>\n",
    "                <li align=\"left\">\n",
    "                    <p>Provide acceptable answers to questions posed in the task template.</p>\n",
    "                </li>\n",
    "            </ul>\n",
    "            <p>The work may be limited in that:</p>\n",
    "            <ul align=\"left\">\n",
    "                <li align=\"left\">\n",
    "                    <p>It may only run on a single machine via PySpark.</p>\n",
    "                </li>\n",
    "                <li align=\"left\">\n",
    "                    <p>It may not demonstrate an attempt at the challenge tasks posed during the block release day.</p>\n",
    "                </li>\n",
    "            </ul>\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>E (30)</td>\n",
    "        <td align=\"left\">\n",
    "            <p>Learning outcomes not met at threshold level, but with additional work a pass could be achieved.  This may mean that code does not run, or solutions are that achieve the brief but without successfully using the Spark infrastructure.</p>\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr style=\"background-color: #FBB36B;\">\n",
    "        <td>F (0-29)</td>\n",
    "        <td align=\"left\">\n",
    "            <p>Learning outcomes not met at threshold level, but with additional work a pass could be achieved.  This may mean that code does not run, or solutions are that achieve the brief but without successfully using the Spark infrastructure.</p>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "<style>\n",
    "    tr:nth-child(odd) {\n",
    "        background-color: orange;\n",
    "    }\n",
    "</style>\n",
    "\n",
    "In addition, for grade of E and above 10 discretionary marks are available for presentation quality of submission (including coding)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f22df12f-1b13-403a-ae02-dd5ecf5e883b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "First you need to establish a Spark Session in a slighlty different way using Spark SQL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "beac37b7-a66a-4b97-a8b9-cedfd02ee477",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import to_date, weekofyear, col, avg, round, abs, udf, length, trim, when\n",
    "from pyspark.sql.types import DoubleType, StringType, IntegerType\n",
    "import spark_utils as su\n",
    "from pyspark.sql.window import Window\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b6ff1ba6-6d46-4ce5-ac40-7c93d80354df",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## Initialise SparkSession (only needed in VS Code - comment out for Databricks)\n",
    "# spark = su.get_spark_session(app_name=\"Task1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "40408a78-dfc0-417c-a9a8-31324d25e929",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## Load JSON data into DataFrame (applicable for VS Code - comment out for Databricks)\n",
    "# file_path = \"data/reviews.json\"\n",
    "# df = su.load_data(spark, file_path, file_format=\"json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0af764de-3895-4057-b7e6-983de17144da",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## Load JSON data into DataFrame (applicable for Databricks Code - comment out for VS Code)\n",
    "\n",
    "# Define GitHub URL and local path on the driver\n",
    "github_raw_url = \"https://raw.githubusercontent.com/UoN-CS/zdat3002-coursework-1-2025-ngudhka/refs/heads/main/data/reviews.json?token=GHSAT0AAAAAADOHB2QNKCTQRPPNSLBR2RZ22JESYWA\"\n",
    "local_file_name = \"reviews.json\" # Just the file name\n",
    "\n",
    "# Download the file to the driver's local filesystem\n",
    "print(f\"Downloading {github_raw_url} to driver's local path: {local_file_name}\")\n",
    "!wget -O {local_file_name} {github_raw_url}\n",
    "\n",
    "# Define the absolute path on the driver's local filesystem\n",
    "driver_local_absolute_path = f\"file:{os.path.abspath(local_file_name)}\"\n",
    "\n",
    "# Define the target path in DBFS\n",
    "dbfs_target_path = f\"/FileStore/reviews/{local_file_name}\"\n",
    "\n",
    "# Ensure the DBFS directory exists\n",
    "dbutils.fs.mkdirs(os.path.dirname(dbfs_target_path))\n",
    "\n",
    "# Copy the file from the driver's local filesystem to DBFS\n",
    "print(f\"Copying from driver's local '{driver_local_absolute_path}' to DBFS '{dbfs_target_path}'...\")\n",
    "dbutils.fs.cp(driver_local_absolute_path, dbfs_target_path)\n",
    "print(\"File copied to DBFS successfully.\")\n",
    "\n",
    "# Load JSON data into DataFrame from the DBFS path\n",
    "print(f\"Loading JSON data from DBFS: {dbfs_target_path}\")\n",
    "df = spark.read.json(dbfs_target_path)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "edf4a692-49c4-4eb7-be54-b2094bfc386a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Having imported the data, take a look at the schema.  Perhaps try running some SQL queries over it.  I've suggested a first example, but you can come up with more questions.\n",
    "\n",
    "**Can you plot how many ratings of each grade are present in the data?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2706e30d-d3e3-485a-b859-171408406c44",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Hints\n",
    "\n",
    "You've loaded your data, and you want to try and process that data remotely as much as possible, only collecting results at the end.\n",
    "\n",
    "You can add columns to the remote DataFrame using\n",
    "\n",
    "df.withColumn(\"myColumnName\", data)\n",
    "\n",
    "You can execute SQL like operations such as group by and order by:\n",
    "\n",
    "df.orderBy(\"columnName\")\n",
    "df.groupBy(\"columnName\")\n",
    "\n",
    "Think about how you would transform the data in the dataframe, and then collect just the data needed to make the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1283abd2-528c-404d-810d-dcfc7236d694",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Inspect the data\n",
    "su.display_df_info(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9617ec94-5fe3-4742-895d-c0158a31213a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create aggregated remote dataframe with count how many ratings of each grade are present. Note grade is represented in the \"overall\" column\n",
    "ratings_distribution = su.get_unique_values(df, \"overall\", order_by_count=False)\n",
    "\n",
    "# take the above remote data frame and convert to Pandas to enable plotting using matplotlib\n",
    "ratings_distribution_pd = ratings_distribution.toPandas()\n",
    "\n",
    "# Generate bar plot for the rating counts\n",
    "su.plot_bar_chart(\n",
    "    data_series=ratings_distribution_pd['count'],\n",
    "    labels=ratings_distribution_pd['overall'],\n",
    "    title=\"Distribution of Ratings\",\n",
    "    x_label=\"Rating Grade\",\n",
    "    y_label=\"Number of Reviews\",\n",
    "    figsize=(8, 5)\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "feb35683-fe20-48c6-a29a-940b919907d9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Can you create a histogram of the number of reviews received on each week of the year.  Are there any patterns present?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "812717c0-5a55-4cb9-80af-bc66a17dadbf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create a new remote dataframe to include the \"Review Date\" and \"Week of Year\"\n",
    "df_with_date_week = df.withColumn(\"reviewDate\", to_date(col(\"reviewTime\"), \"MM d, yyyy\")) \\\n",
    "                      .withColumn(\"weekOfYear\", weekofyear(col(\"reviewDate\")))\n",
    "\n",
    "# Use new remote dataframe to generated an remote aggregated dataframe for counts by week\n",
    "reviews_per_week = su.get_unique_values(df_with_date_week, \"weekOfYear\", order_by_count=False)\n",
    "\n",
    "# take the above remote data frame and convert to Pandas to enable plotting using matplotlib\n",
    "reviews_per_week_pd = reviews_per_week.toPandas()\n",
    "\n",
    "# Generate bar plot for the review count per week\n",
    "su.plot_bar_chart(\n",
    "    data_series=reviews_per_week_pd['count'],\n",
    "    labels=reviews_per_week_pd['weekOfYear'],\n",
    "    title=\"Number of Reviews per Week of the Year\",\n",
    "    x_label=\"Week of the Year\",\n",
    "    y_label=\"Number of Reviews\",\n",
    "    figsize=(15, 6),\n",
    "    rotation=45 # Rotate labels if they overlap\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "33a41a5e-cf72-4f27-bd0a-1591a0d523c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Based on the histogram of the number of reviews received each week of the year, here are the patterns I observe:\n",
    "\n",
    "1. Overall Consistency: The most prominent pattern is a relatively consistent number of reviews throughout the year. There aren't massive spikes or dramatic drops, suggesting a steady stream of reviews rather than highly seasonal or event-driven review behavior.\n",
    "2. Slight Mid-Year Dip: There appears to be a minor dip in the number of reviews during the middle part of the year, roughly from Week 21 to Week 32 (which corresponds to late May through early August). Review counts during these weeks are often slightly lower than the annual average. This could potentially be attributed to summer holidays when people might be less active in submitting product reviews.\n",
    "3. Minor Increases in Spring and Autumn: Conversely, there are minor upticks in review activity during the spring (around Weeks 13-16, March/April) and autumn (around Weeks 38-44, September/October). These periods might correlate with general shopping seasons or specific product releases that aren't tied to major annual holidays.\n",
    "4. Absence of Major Holiday Spikes: Interestingly, despite common retail trends, there isn't a significant surge in reviews around major shopping holidays like Thanksgiving, Black Friday, or Christmas (which would typically fall in Weeks 47-52). The review counts in these weeks remain largely in line with the rest of the year, indicating that the products being reviewed might be heavily gift-oriented.\n",
    "5. No Extreme Outliers: No single week stands out as an extreme outlier with an exceptionally high or\n",
    "low number of reviews, reinforcing the idea of a stable and predictable review generation process\n",
    "for this dataset.\n",
    "\n",
    "In summary, the pattern suggests a product category or customer base that provides reviews at a fairly constant rate throughout the year, with only subtle seasonal variations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb1a6474-6d26-485a-af53-efd98594f95b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Can you think of your own query?**\n",
    "\n",
    "Let's identify reviews that are deviating from reviewer's average ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4160504c-d825-475b-85c0-86ffac80efd6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Let's set a deviation threshold\n",
    "deviation_threshold = 1.5\n",
    "\n",
    "# Define the window specification for defining the average calculation on a particular row.\n",
    "# We want to take the average rating for a particular reviewer ID\n",
    "window_spec = Window.partitionBy(\"reviewerID\")\n",
    "\n",
    "# Add a new column with the reviewer's average rating using PySpark's window function (avg().over())\n",
    "df_with_reviewer_avg = df.withColumn(\"reviewerAvgRating\",\n",
    "    round(avg(col(\"overall\")).over(window_spec), 2) \n",
    ")\n",
    "\n",
    "# Add a new column to calculate the deviation from the reviewer's average rating\n",
    "# using the PySpark column operations\n",
    "df_with_deviation = df_with_reviewer_avg.withColumn(\"ratingDeviation\",\n",
    "    round(col(\"overall\") - col(\"reviewerAvgRating\"), 2) # Direct PySpark function usage\n",
    ")\n",
    "\n",
    "# Filter the DataFrame to find reviews where the absolute deviation is significant\n",
    "# using PySpark column conditions (abs())\n",
    "unusual_reviews_df = df_with_deviation.filter(\n",
    "    abs(col(\"ratingDeviation\")) >= deviation_threshold # Direct PySpark function usage\n",
    ")\n",
    "\n",
    "# Select only the relevant columns for inspection\n",
    "unusual_reviews_for_display_df = unusual_reviews_df.select(\n",
    "    [\"reviewerID\", \"overall\", \"reviewerAvgRating\", \"ratingDeviation\", \"asin\", \"reviewText\", \"summary\"]\n",
    ")\n",
    "\n",
    "# Order the results for better readability, showing the largest deviations first\n",
    "ordered_unusual_reviews_df = unusual_reviews_for_display_df.orderBy(\n",
    "    [\"ratingDeviation\"], # Order by deviation magnitude\n",
    "    ascending=False      # Show largest positive deviations first\n",
    ")\n",
    "\n",
    "print(f\"Reviews where individual rating deviates from reviewer's average by >= {deviation_threshold} stars:\")\n",
    "\n",
    "ordered_unusual_reviews_df.show(n=20, truncate=False)\n",
    "\n",
    "print(\"-----------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b7b7b27-601d-48c8-9dc5-e8d99c3e1a31",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Task 1 stretch task.\n",
    "\n",
    "Can you calculate the sentiment score for each review?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3623c731-a718-42b2-b785-f1abf76c9173",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load JSON data into DataFrame from the DBFS path\n",
    "df = spark.read.json(\"/mnt/reviews/clothing.json\")\n",
    "\n",
    "# View df info\n",
    "su.display_df_info(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "be1e57f4-172b-408c-9f2e-90064e36ef12",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Get AFINN-111 file for sentiment analysis\n",
    "afinn_path = \"file:////Workspace/Users/scyng2@nottingham.ac.uk/zdat3002-coursework-1-2025-ngudhka/data/AFINN-111.txt\"\n",
    "lines = spark.read.text(afinn_path).rdd.map(lambda r: r[0]).collect()\n",
    " \n",
    "# Check if lines read\n",
    "print(f\"Read {len(lines)} lines. First line: {lines[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f0645277-2de3-469a-8ce1-0d61e112b20d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load AFINN lexicon into a Python dictionary\n",
    "afinn_map = {}\n",
    "try:\n",
    "    for line in lines: # Iterate through the collected Python list 'lines'\n",
    "        parts = line.strip().split('\\t')\n",
    "        if len(parts) == 2:\n",
    "            word, score = parts\n",
    "            afinn_map[word] = int(score)\n",
    "        else:\n",
    "            print(f\"Skipping malformed line in AFINN file: {line.strip()}\")\n",
    "except Exception as e: # Catch any potential errors during dictionary creation\n",
    "    print(f\"Error processing AFINN lexicon: {e}\")\n",
    "    spark.stop()\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d46501c5-27c9-4348-a071-8f8332cb54d6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Broadcast the AFINN lexicon to all worker nodes\n",
    "broadcast_afinn = sc.broadcast(afinn_map)\n",
    "print(f\"AFINN lexicon loaded and broadcasted. Contains {len(afinn_map)} terms.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "69c169ed-6ac4-4d3a-ae9f-e9555a8e09df",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define the UDF for sentiment scoring \n",
    "def get_sentiment_score(text):\n",
    "    if text is None:\n",
    "        return None\n",
    "    if not isinstance(text, str):\n",
    "        return None\n",
    "    cleaned_text = text.strip()\n",
    "    if not cleaned_text:\n",
    "        return float(0)\n",
    "    words = text.lower().split()\n",
    "    if not words:\n",
    "        return float(0)\n",
    "    score = sum(broadcast_afinn.value.get(word, 0) for word in words)\n",
    "    return score\n",
    "\n",
    "sentiment_udf = udf(get_sentiment_score, IntegerType())\n",
    "print(\"Sentiment UDF registered.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b0fd3c7-90f0-435a-83e4-0e3c9dfde2aa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create a new column for the sentiment score and run the sentiment score function to populate it\n",
    "df_with_sentiment = df.withColumn(\"sentiment_score\", sentiment_udf(col(\"reviewText\")))\n",
    "\n",
    "# Display some reviews with their sentiment scores.\n",
    "print(\"DataFrame with sentiment scores:\")\n",
    "df_with_sentiment.select(\"overall\", \"reviewText\", \"sentiment_score\").show(10, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2cb64c45-3ce9-4c80-8c00-69e3176ac75d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "How can you visualise this sentiment in a useful way?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "acc76a7b-f0c5-4831-b2b5-4724934b84ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import seaborn as sns# Box plot of sentiment scores grouped by overall rating\n",
    "\n",
    "df_with_sentiment_pd = df_with_sentiment.select(\"overall\", \"sentiment_score\").toPandas()\n",
    "\n",
    "# Sample a subset to avoid driver OOM when converting to pandas\n",
    "sample_fraction = 0.05  # Adjust as needed for your cluster size\n",
    "df_sampled = df_with_sentiment.select(\"overall\", \"sentiment_score\").sample(fraction=sample_fraction, seed=42)\n",
    "df_with_sentiment_pd = df_sampled.toPandas()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x=\"overall\", y=\"sentiment_score\", data=df_with_sentiment_pd, palette=\"Set2\")\n",
    "plt.title(\"Sentiment Score Distribution by Overall Rating\")\n",
    "plt.xlabel(\"Overall Rating\")\n",
    "plt.ylabel(\"Sentiment Score\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d245a06-c9b0-4bce-86ed-5503c3b5d2f0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "From the above plot it is difficult to see the correlation given the wide range of data points. Let's focus in on the sections of the plots excluding the tail points.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eb179e33-a859-4d38-87f4-65f6076f4e8c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Plot the boxplot without showing outlier (tail) points\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x=\"overall\", y=\"sentiment_score\", data=df_with_sentiment_pd, palette=\"Set2\", showfliers=False)\n",
    "plt.title(\"Sentiment Score Distribution by Overall Rating (No Outliers)\")\n",
    "plt.xlabel(\"Overall Rating\")\n",
    "plt.ylabel(\"Sentiment Score\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f740edd6-bae7-4abb-94d9-eb304ee1414a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "From the above plot we can now see that there is a clear correlation between overall rating and sentiment score. Higher sentiment scores correspond to higher overall ratings.\n",
    "\n",
    "Now let's see if we can get a similar plot output considering the whole dataset, not just a sample. To do this we will have to compute the quantile statistics using pyspark functions, and output just the stats for plotting, not the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1255fff0-1b12-4326-9779-a460ba1b38fb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "\n",
    "# Compute approximate quantiles  #\n",
    "quantiles = df_with_sentiment.groupBy(\"overall\").agg(\n",
    "    F.expr(\"percentile_approx(sentiment_score, array(0.0, 0.25, 0.5, 0.75, 1.0)) as qs\")\n",
    ")\n",
    "\n",
    "# Unpack quantiles into separate columns\n",
    "quantiles = quantiles.select(\n",
    "    \"overall\",\n",
    "    F.col(\"qs\")[0].alias(\"min\"),\n",
    "    F.col(\"qs\")[1].alias(\"q1\"),\n",
    "    F.col(\"qs\")[2].alias(\"median\"),\n",
    "    F.col(\"qs\")[3].alias(\"q3\"),\n",
    "    F.col(\"qs\")[4].alias(\"max\")\n",
    ")\n",
    "\n",
    "pdf = quantiles.orderBy(\"overall\").toPandas()\n",
    "\n",
    "# Plot using matplotlib\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "box_data = []\n",
    "labels = []\n",
    "\n",
    "for _, row in pdf.iterrows():\n",
    "    box_data.append({\n",
    "        \"whislo\": row[\"min\"],\n",
    "        \"q1\": row[\"q1\"],\n",
    "        \"med\": row[\"median\"],\n",
    "        \"q3\": row[\"q3\"],\n",
    "        \"whishi\": row[\"max\"],\n",
    "        \"fliers\": []\n",
    "    })\n",
    "    labels.append(str(row[\"overall\"]))\n",
    "\n",
    "plt.boxplot([[d['whislo'], d['q1'], d['med'], d['q3'], d['whishi']] for d in box_data], showfliers=False)\n",
    "plt.xticks(range(1, len(labels)+1), labels)\n",
    "plt.xlabel(\"Overall Rating\")\n",
    "plt.ylabel(\"Sentiment Score\")\n",
    "plt.title(\"Sentiment Score Distribution by Rating (Approx Quantiles)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f7b5963d-fac8-4f4d-83a5-01757fed3b98",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "The above plot corresponds well to the earlier sample plot. So both are valid techniques for capturing the effectiveness of the sentiment scoring."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "COMP3002 Task 1",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
